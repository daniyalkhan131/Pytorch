{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "XAGxfbKmd2-d",
        "outputId": "81c0993d-23bd-4911-ab54-6139ea75b337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-metric-learning\n",
            "  Downloading pytorch_metric_learning-2.5.0-py3-none-any.whl (119 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.1/119.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (1.2.2)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from pytorch-metric-learning) (4.66.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->pytorch-metric-learning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->pytorch-metric-learning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->pytorch-metric-learning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->pytorch-metric-learning) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->pytorch-metric-learning) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->pytorch-metric-learning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-metric-learning\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch-metric-learning-2.5.0\n",
            "Collecting faiss-gpu\n",
            "  Downloading faiss_gpu-1.7.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (85.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-gpu\n",
            "Successfully installed faiss-gpu-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-metric-learning\n",
        "!pip install faiss-gpu\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision\n",
        "import umap.umap_ as umap\n",
        "from cycler import cycler\n",
        "import logging\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from pytorch_metric_learning import distances, losses, miners, reducers, testers, trainers\n",
        "from pytorch_metric_learning.utils.accuracy_calculator import AccuracyCalculator\n",
        "\n",
        "import pytorch_metric_learning.utils.logging_presets as logging_presets\n",
        "\n",
        "from pytorch_metric_learning.samplers import MPerClassSampler"
      ],
      "metadata": {
        "id": "Jg_-shSaePF2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
        "        self.dropout1 = nn.Dropout2d(0.25)\n",
        "        self.dropout2 = nn.Dropout2d(0.5)\n",
        "        self.fc1 = nn.Linear(9216, 128)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "552rpRjUezAB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### MNIST code originally from https://github.com/pytorch/examples/blob/master/mnist/main.py ###\n",
        "def train(model, loss_func, mining_func, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, labels) in enumerate(train_loader):\n",
        "        data, labels = data.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        embeddings = model(data)\n",
        "        indices_tuple = mining_func(embeddings, labels)\n",
        "        loss = loss_func(embeddings, labels, indices_tuple)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if batch_idx % 20 == 0:\n",
        "            print(\n",
        "                \"Epoch {} Iteration {}: Loss = {}, Number of mined triplets = {}\".format(\n",
        "                    epoch, batch_idx, loss, mining_func.num_triplets\n",
        "                )\n",
        "            )"
      ],
      "metadata": {
        "id": "wrxL2FcnfNLW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### convenient function from pytorch-metric-learning ###\n",
        "def get_all_embeddings(dataset, model):\n",
        "    tester = testers.BaseTester()\n",
        "    return tester.get_all_embeddings(dataset, model)\n"
      ],
      "metadata": {
        "id": "uVH9K2sKfYNZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "### compute accuracy using AccuracyCalculator from pytorch-metric-learning ###\n",
        "def test(train_set, test_set, model, accuracy_calculator):\n",
        "    train_embeddings, train_labels = get_all_embeddings(train_set, model)\n",
        "    test_embeddings, test_labels = get_all_embeddings(test_set, model)\n",
        "    train_labels = train_labels.squeeze(1)\n",
        "    test_labels = test_labels.squeeze(1)\n",
        "    print(\"Computing accuracy\")\n",
        "    accuracies = accuracy_calculator.get_accuracy(\n",
        "        test_embeddings, test_labels, train_embeddings, train_labels, False\n",
        "    )\n",
        "    print(\"Test set accuracy (Precision@1) = {}\".format(accuracies[\"precision_at_1\"]))"
      ],
      "metadata": {
        "id": "gpOFHMFsgJLy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
        ")\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "dataset1 = datasets.MNIST(\".\", train=True, download=True, transform=transform)\n",
        "dataset2 = datasets.MNIST(\".\", train=False, transform=transform)\n",
        "train_sampler = MPerClassSampler(dataset1.targets, m=4) #sampler for 4 datapoints per class\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    dataset1, batch_size=batch_size, shuffle=False, sampler= train_sampler\n",
        ")\n",
        "test_loader = torch.utils.data.DataLoader(dataset2, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "p4HpmoHnglOj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Net().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "num_epochs = 2\n",
        "\n",
        "\n",
        "### pytorch-metric-learning stuff ###\n",
        "distance = distances.CosineSimilarity()\n",
        "reducer = reducers.ThresholdReducer(low=0)\n",
        "loss_func = losses.TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
        "mining_func = miners.TripletMarginMiner(\n",
        "    margin=0.2, distance=distance, type_of_triplets=\"semihard\"\n",
        ")\n",
        "accuracy_calculator = AccuracyCalculator(include=(\"precision_at_1\",), k=1)\n",
        "### pytorch-metric-learning stuff ###\n",
        "\n",
        "\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    train(model, loss_func, mining_func, device, train_loader, optimizer, epoch)\n",
        "    test(dataset1, dataset2, model, accuracy_calculator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qa7D2X87nqHo",
        "outputId": "bdd710e6-f169-4ca3-b538-b873fca7953b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Iteration 0: Loss = 0.10672411322593689, Number of mined triplets = 831023\n",
            "Epoch 1 Iteration 20: Loss = 0.09169085323810577, Number of mined triplets = 91612\n",
            "Epoch 1 Iteration 40: Loss = 0.08725952357053757, Number of mined triplets = 62340\n",
            "Epoch 1 Iteration 60: Loss = 0.08429042994976044, Number of mined triplets = 45409\n",
            "Epoch 1 Iteration 80: Loss = 0.08533218502998352, Number of mined triplets = 48165\n",
            "Epoch 1 Iteration 100: Loss = 0.0827733650803566, Number of mined triplets = 35447\n",
            "Epoch 1 Iteration 120: Loss = 0.08189624547958374, Number of mined triplets = 30935\n",
            "Epoch 1 Iteration 140: Loss = 0.08429250121116638, Number of mined triplets = 29141\n",
            "Epoch 1 Iteration 160: Loss = 0.0801670178771019, Number of mined triplets = 23155\n",
            "Epoch 1 Iteration 180: Loss = 0.08094586431980133, Number of mined triplets = 18762\n",
            "Epoch 1 Iteration 200: Loss = 0.08416017889976501, Number of mined triplets = 19353\n",
            "Epoch 1 Iteration 220: Loss = 0.08524766564369202, Number of mined triplets = 22677\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 114.66it/s]\n",
            "100%|██████████| 313/313 [00:02<00:00, 122.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.9828\n",
            "Epoch 2 Iteration 0: Loss = 0.08110182732343674, Number of mined triplets = 19178\n",
            "Epoch 2 Iteration 20: Loss = 0.08309600502252579, Number of mined triplets = 17785\n",
            "Epoch 2 Iteration 40: Loss = 0.08153527975082397, Number of mined triplets = 20730\n",
            "Epoch 2 Iteration 60: Loss = 0.07751911878585815, Number of mined triplets = 16077\n",
            "Epoch 2 Iteration 80: Loss = 0.08110570162534714, Number of mined triplets = 22225\n",
            "Epoch 2 Iteration 100: Loss = 0.08376365154981613, Number of mined triplets = 20176\n",
            "Epoch 2 Iteration 120: Loss = 0.08577261865139008, Number of mined triplets = 26528\n",
            "Epoch 2 Iteration 140: Loss = 0.08315284550189972, Number of mined triplets = 18558\n",
            "Epoch 2 Iteration 160: Loss = 0.08728939294815063, Number of mined triplets = 22372\n",
            "Epoch 2 Iteration 180: Loss = 0.08220931142568588, Number of mined triplets = 15424\n",
            "Epoch 2 Iteration 200: Loss = 0.08564545214176178, Number of mined triplets = 19011\n",
            "Epoch 2 Iteration 220: Loss = 0.08136245608329773, Number of mined triplets = 17968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1875/1875 [00:16<00:00, 114.63it/s]\n",
            "100%|██████████| 313/313 [00:04<00:00, 78.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computing accuracy\n",
            "Test set accuracy (Precision@1) = 0.9846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IRo3lAAcpDom"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### inference"
      ],
      "metadata": {
        "id": "nYwEhqXwvVxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_metric_learning.utils import common_functions as c_f\n",
        "from pytorch_metric_learning.utils.inference import InferenceModel, MatchFinder"
      ],
      "metadata": {
        "id": "irfPDHBTvW01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_decision(is_match):\n",
        "    if is_match:\n",
        "        print(\"Same class\")\n",
        "    else:\n",
        "        print(\"Different class\")\n",
        "\n",
        "\n",
        "mean = [0.485, 0.456, 0.406]\n",
        "std = [0.229, 0.224, 0.225]\n",
        "\n",
        "inv_normalize = transforms.Normalize(\n",
        "    mean=[-m / s for m, s in zip(mean, std)], std=[1 / s for s in std]\n",
        ")\n",
        "\n",
        "\n",
        "def imshow(img, figsize=(8, 4)):\n",
        "    img = inv_normalize(img)\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "yfSpb_pHvXxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "match_finder = MatchFinder(distance=distances.CosineSimilarity(), threshold=0.7)\n",
        "inference_model = InferenceModel(model, match_finder=match_finder)\n",
        "\n",
        "# cars and frogs\n",
        "classA, classB = labels_to_indices[1], labels_to_indices[6]"
      ],
      "metadata": {
        "id": "9llRUzOyvXvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inference_model.train_knn(dataset1)"
      ],
      "metadata": {
        "id": "HNIU-AAlvXth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for img_type in [classA, classB]:\n",
        "    img = dataset1[img_type[0]][0].unsqueeze(0)\n",
        "    print(\"query image\")\n",
        "    imshow(torchvision.utils.make_grid(img))\n",
        "    distances, indices = inference_model.get_nearest_neighbors(img, k=10)\n",
        "    nearest_imgs = [dataset1[i][0] for i in indices.cpu()[0]]\n",
        "    print(\"nearest images\")\n",
        "    imshow(torchvision.utils.make_grid(nearest_imgs))"
      ],
      "metadata": {
        "id": "1K8gY0yZvXrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x, _), (y, _) = dataset1[classA[0]], dataset1[classA[1]]\n",
        "imshow(torchvision.utils.make_grid(torch.stack([x, y], dim=0)))\n",
        "decision = inference_model.is_match(x.unsqueeze(0), y.unsqueeze(0))\n",
        "print_decision(decision)"
      ],
      "metadata": {
        "id": "YJRP9rUrvXpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(x, _), (y, _) = dataset1[classA[0]], dataset1[classB[0]]\n",
        "imshow(torchvision.utils.make_grid(torch.stack([x, y], dim=0)))\n",
        "decision = inference_model.is_match(x.unsqueeze(0), y.unsqueeze(0))\n",
        "print_decision(decision)"
      ],
      "metadata": {
        "id": "70HACmIPvXni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.zeros(20, 1, 28, 28)\n",
        "y = torch.zeros(20, 1, 28, 28)\n",
        "for i in range(0, 20, 2):\n",
        "    x[i] = dataset1[classA[i]][0]\n",
        "    x[i + 1] = dataset1[classB[i]][0]\n",
        "    y[i] = dataset1[classA[i + 20]][0]\n",
        "    y[i + 1] = dataset1[classB[i + 20]][0]\n",
        "imshow(torchvision.utils.make_grid(torch.cat((x, y), dim=0), nrow=20), figsize=(30, 3))\n",
        "decision = inference_model.is_match(x, y)\n",
        "for d in decision:\n",
        "    print_decision(d)\n",
        "print(\"accuracy = {}\".format(np.sum(decision) / len(x)))"
      ],
      "metadata": {
        "id": "cXbfnBPFvhzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using trainer of pytorch_metric_learn, we also built umap in this"
      ],
      "metadata": {
        "id": "syGbGSCIv83t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\"trunk\": model}\n",
        "optimizers = {\n",
        "    \"trunk_optimizer\": optimizer\n",
        "}\n",
        "loss_funcs = {\"metric_loss\": loss_func}\n",
        "mining_funcs = {\"tuple_miner\": miner}\n",
        "\n",
        "dataset_dict = {\"val\": dataset2}\n"
      ],
      "metadata": {
        "id": "RZOkWaQywBsI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_keeper, _, _ = logging_presets.get_record_keeper(\n",
        "    \"example_logs\", \"example_tensorboard\"\n",
        ")\n",
        "hooks = logging_presets.get_hook_container(record_keeper)\n",
        "model_folder = \"example_saved_models\"\n",
        "\n",
        "\n",
        "def visualizer_hook(umapper, umap_embeddings, labels, split_name, keyname, *args):\n",
        "    logging.info(\n",
        "        \"UMAP plot for the {} split and label set {}\".format(split_name, keyname)\n",
        "    )\n",
        "    label_set = np.unique(labels)\n",
        "    num_classes = len(label_set)\n",
        "    plt.figure(figsize=(20, 15))\n",
        "    plt.gca().set_prop_cycle(\n",
        "        cycler(\n",
        "            \"color\", [plt.cm.nipy_spectral(i) for i in np.linspace(0, 0.9, num_classes)]\n",
        "        )\n",
        "    )\n",
        "    for i in range(num_classes):\n",
        "        idx = labels == label_set[i]\n",
        "        plt.plot(umap_embeddings[idx, 0], umap_embeddings[idx, 1], \".\", markersize=1)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# Create the tester\n",
        "tester = testers.GlobalEmbeddingSpaceTester(\n",
        "    end_of_testing_hook=hooks.end_of_testing_hook,\n",
        "    visualizer=umap.UMAP(),\n",
        "    visualizer_hook=visualizer_hook,\n",
        "    dataloader_num_workers=2,\n",
        "    accuracy_calculator=AccuracyCalculator(k=\"max_bin_count\"),\n",
        ")\n",
        "\n",
        "end_of_epoch_hook = hooks.end_of_epoch_hook(\n",
        "    tester, dataset_dict, model_folder#, test_interval=1, patience=1\n",
        ")"
      ],
      "metadata": {
        "id": "Xd4YPjwZwBqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = trainers.MetricLossOnly(\n",
        "    models,\n",
        "    optimizers,\n",
        "    batch_size,\n",
        "    loss_funcs,\n",
        "    dataset1,\n",
        "    mining_funcs=mining_funcs,\n",
        "    sampler=train_sampler,\n",
        "    dataloader_num_workers=2,\n",
        "    end_of_iteration_hook=hooks.end_of_iteration_hook,\n",
        "    end_of_epoch_hook=end_of_epoch_hook,\n",
        ")"
      ],
      "metadata": {
        "id": "a09GgGpGwBov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train(num_epochs=num_epochs)"
      ],
      "metadata": {
        "id": "3qpmAxb0wBmv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}