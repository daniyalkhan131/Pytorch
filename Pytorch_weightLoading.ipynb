{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AoEGkbUZ4xct"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import collections\n",
        "\n",
        "# Define a simple neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 50)\n",
        "        self.fc2 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleNN()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "I-fqFgxF4-Jd"
      },
      "outputs": [],
      "source": [
        "state_dict = collections.OrderedDict([\n",
        "    ('fc1.weight', torch.randn(50, 10)),\n",
        "    ('fc1.bias', torch.randn(50)),\n",
        "    ('fc2.weight', torch.randn(1, 50)),\n",
        "    ('fc2.bias', torch.randn(1))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQ78su7E5ACF",
        "outputId": "020c1cee-16de-457f-f102-c9578fd7807f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SimpleNN(\n",
              "  (fc1): Linear(in_features=10, out_features=50, bias=True)\n",
              "  (fc2): Linear(in_features=50, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(state_dict)\n",
        "model.eval()\n",
        "\n",
        "#model name is the class we made for model and directly can load weights that is in ordered collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ubcAUjd5R8-"
      },
      "outputs": [],
      "source": [
        "#for checking if weights updated or not\n",
        "#first do this then initial_state_dict = model.state_dict()\n",
        "for key in initial_state_dict:\n",
        "    if not torch.equal(initial_state_dict[key], model.state_dict()[key]):\n",
        "        print(f'Layer {key} weights have been updated.')\n",
        "    else:\n",
        "        print(f'Layer {key} weights have NOT been updated.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNxaHzN74Neb"
      },
      "outputs": [],
      "source": [
        "#we can see model that if grad prop possible or not"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "pytorch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
